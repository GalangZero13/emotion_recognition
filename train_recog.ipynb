{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_recog.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWDikeY46i8H",
        "colab_type": "text"
      },
      "source": [
        "# IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ba2JsFRfuzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import emotion_config as config\n",
        "from imagetoarraypreprocessor import ImageToArrayPreprocessor\n",
        "#from epochcheckpoint import EpochCheckpoint\n",
        "from trainingmonitor import TrainingMonitor\n",
        "from emotionvggnet import EmotionVGGNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbaXaLwF5YQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "import keras.backend as K \n",
        "import argparse\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH_9WHNA6Nwv",
        "colab_type": "text"
      },
      "source": [
        "#Self Imported Library\n",
        "HDF5 Dataset Generator, because the py file isn't actually working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dftB5vdf2J0K",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title HDF5 Dataset Generator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "class HDF5DatasetGenerator:\n",
        "    def __init__(self, dbPath, batchSize, preprocessors = None, aug = None, binarize = True, classes = 2):\n",
        "\n",
        "        self.batchSize = batchSize\n",
        "        self.preprocessors = preprocessors\n",
        "        self.aug = aug\n",
        "        self.binarize = binarize\n",
        "        self.classes = classes\n",
        "\n",
        "        self.db = h5py.File(dbPath)\n",
        "        self.numImages = self.db[\"labels\"].shape[0]\n",
        "\n",
        "    def generator(self, passes = np.inf):\n",
        "        epochs = 0\n",
        "        while epochs < passes:\n",
        "            for i in np.arange(0, self.numImages, self.batchSize):\n",
        "\n",
        "                images = self.db[\"images\"][i: i + self.batchSize]\n",
        "                labels = self.db[\"labels\"][i: i + self.batchSize]\n",
        "\n",
        "                if self.binarize:\n",
        "                    labels = np_utils.to_categorical(labels, self.classes)\n",
        "                    \n",
        "                if self.preprocessors is not None:\n",
        "                    procImages = []\n",
        "                    for image in images:\n",
        "                        for p in self.preprocessors:\n",
        "                            image = p.preprocess(image)\n",
        "                        procImages.append(image)\n",
        "                    images = np.array(procImages)\n",
        "                \n",
        "                if self.aug is not None:\n",
        "                    (images, labels) = next(self.aug.flow(images, labels, batch_size = self.batchSize))\n",
        "                \n",
        "                yield(images, labels)\n",
        "            epochs += 1\n",
        "\n",
        "    def close(self):\n",
        "        self.db.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQfqEkBQBBiN",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Epoch Checkpoint\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class EpochCheckpoint(Callback):\n",
        "    def __init__(self, outputPath, every = 5, startAt = 0):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.outputPath = outputPath\n",
        "        self.every = every\n",
        "        self.intEpoch = startAt\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "        if (self.intEpoch + 1) % self.every == 0:\n",
        "            p = os.path.sep.join([self.outputPath, \"epoch_{}.hdf5\".format(self.intEpoch + 1)])\n",
        "            self.model.save(p, overwrite = True)\n",
        "\n",
        "        self.intEpoch += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbLWU79p6t3t",
        "colab_type": "text"
      },
      "source": [
        "# Argument Parsing and Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpEZtG1KP-Bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-c\", \"--checkpoints\", required = True, help = \"path to output checkpoint directory\")\n",
        "ap.add_argument(\"-m\", \"--model\", type = str, help = \"path to *specific* model checkpoint to load\")\n",
        "ap.add_argument(\"-s\", \"--start-epoch\", type = int, default = 0, help = \"epoch to restart training at\")\n",
        "#args = vars(ap.parse_args())\n",
        "args = vars(ap.parse_args([\"--checkpoints\", \"checkpoints\", \"--model\", \"checkpoints/epoch_30.hdf5\", \"--start-epoch\", \"30\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7HnWt_6QAyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainAug = ImageDataGenerator(rotation_range = 10, zoom_range = 0.1, horizontal_flip = True, rescale = 1/255.0, fill_mode = \"nearest\")\n",
        "valAug = ImageDataGenerator(rescale = 1/255.0)\n",
        "iap = ImageToArrayPreprocessor()\n",
        "\n",
        "trainGen = HDF5DatasetGenerator(config.TRAIN_HDF5, config.BATCH_SIZE, aug = trainAug, preprocessors = [iap], classes = config.NUM_CLASSES)\n",
        "valGen = HDF5DatasetGenerator(config.VAL_HDF5, config.BATCH_SIZE, aug = valAug, preprocessors = [iap], classes = config.NUM_CLASSES)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0lBThWMQOTD",
        "colab_type": "code",
        "outputId": "6fad97aa-75b8-4493-ecf1-81ab44b16d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "if args[\"model\"] is None:\n",
        "    print(\"[INFO] compiling model...\")\n",
        "    model = EmotionVGGNet.build(width = 48, height = 48, depth = 1, classes = config.NUM_CLASSES)\n",
        "    opt = Adam(lr = 1e-3)\n",
        "    model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "else:\n",
        "    print(\"[INFO] loading {}...\".format(args[\"model\"]))\n",
        "    model = load_model(args[\"model\"])\n",
        "\n",
        "    print(\"[INFO] old learning rate: {}\".format(K.get_value(model.optimizer.lr)))\n",
        "    K.set_value(model.optimizer.lr, 1e-3)\n",
        "    print(\"[INFO] new learning rate: {}\".format(K.get_value(model.optimizer.lr)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading checkpoints/epoch_30.hdf5...\n",
            "[INFO] old learning rate: 0.0010000000474974513\n",
            "[INFO] new learning rate: 0.0010000000474974513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-nluaADRXvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "figPath = os.path.sep.join([config.OUTPUT_PATH, \"vggnet_emotion.json\"])\n",
        "jsonPath = os.path.sep.join([config.OUTPUT_PATH, \"vggnet_emotion.json\"])\n",
        "callbacks = [\n",
        "    EpochCheckpoint(args[\"checkpoints\"], every = 5, startAt = args[\"start_epoch\"])\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Us7YRfT7FdG",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3SmMKXNRaNA",
        "colab_type": "code",
        "outputId": "f9ca5e80-f8cb-4d89-a455-893deb7accfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    trainGen.generator(),\n",
        "    steps_per_epoch = trainGen.numImages // config.BATCH_SIZE,\n",
        "    validation_data = valGen.generator(),\n",
        "    validation_steps = valGen.numImages // config.BATCH_SIZE,\n",
        "    epochs = 60,\n",
        "    max_queue_size = config.BATCH_SIZE * 2,\n",
        "    callbacks = callbacks,\n",
        "    verbose = 1)\n",
        "\n",
        "trainGen.close()\n",
        "valGen.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "224/224 [==============================] - 20s 90ms/step - loss: 1.0165 - acc: 0.6317 - val_loss: 0.8379 - val_acc: 0.6883\n",
            "Epoch 2/60\n",
            "224/224 [==============================] - 15s 66ms/step - loss: 1.0088 - acc: 0.6375 - val_loss: 0.8561 - val_acc: 0.6882\n",
            "Epoch 3/60\n",
            "224/224 [==============================] - 15s 67ms/step - loss: 1.0078 - acc: 0.6343 - val_loss: 0.8956 - val_acc: 0.6816\n",
            "Epoch 4/60\n",
            "224/224 [==============================] - 15s 65ms/step - loss: 0.9987 - acc: 0.6390 - val_loss: 0.8505 - val_acc: 0.6949\n",
            "Epoch 5/60\n",
            "224/224 [==============================] - 14s 65ms/step - loss: 0.9932 - acc: 0.6377 - val_loss: 0.8925 - val_acc: 0.7007\n",
            "Epoch 6/60\n",
            "224/224 [==============================] - 11s 48ms/step - loss: 0.9823 - acc: 0.6444 - val_loss: 0.8691 - val_acc: 0.6940\n",
            "Epoch 7/60\n",
            "224/224 [==============================] - 11s 47ms/step - loss: 0.9757 - acc: 0.6469 - val_loss: 0.8061 - val_acc: 0.7033\n",
            "Epoch 8/60\n",
            "224/224 [==============================] - 11s 48ms/step - loss: 0.9721 - acc: 0.6478 - val_loss: 0.7867 - val_acc: 0.7059\n",
            "Epoch 9/60\n",
            "224/224 [==============================] - 14s 61ms/step - loss: 0.9693 - acc: 0.6533 - val_loss: 0.7845 - val_acc: 0.7059\n",
            "Epoch 10/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.9622 - acc: 0.6473 - val_loss: 0.9594 - val_acc: 0.7085\n",
            "Epoch 11/60\n",
            "224/224 [==============================] - 14s 65ms/step - loss: 0.9588 - acc: 0.6534 - val_loss: 0.8277 - val_acc: 0.7105\n",
            "Epoch 12/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.9481 - acc: 0.6577 - val_loss: 0.8245 - val_acc: 0.7200\n",
            "Epoch 13/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.9489 - acc: 0.6592 - val_loss: 0.8250 - val_acc: 0.7070\n",
            "Epoch 14/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.9354 - acc: 0.6623 - val_loss: 0.8619 - val_acc: 0.7082\n",
            "Epoch 15/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.9313 - acc: 0.6628 - val_loss: 0.8256 - val_acc: 0.7142\n",
            "Epoch 16/60\n",
            "224/224 [==============================] - 15s 65ms/step - loss: 0.9303 - acc: 0.6637 - val_loss: 0.9358 - val_acc: 0.6923\n",
            "Epoch 17/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.9253 - acc: 0.6653 - val_loss: 0.8964 - val_acc: 0.6986\n",
            "Epoch 18/60\n",
            "224/224 [==============================] - 14s 65ms/step - loss: 0.9310 - acc: 0.6651 - val_loss: 0.9006 - val_acc: 0.7134\n",
            "Epoch 19/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.9189 - acc: 0.6687 - val_loss: 0.8639 - val_acc: 0.7168\n",
            "Epoch 20/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.9082 - acc: 0.6715 - val_loss: 1.0046 - val_acc: 0.7125\n",
            "Epoch 21/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.9099 - acc: 0.6711 - val_loss: 0.8825 - val_acc: 0.7050\n",
            "Epoch 22/60\n",
            "224/224 [==============================] - 15s 65ms/step - loss: 0.9056 - acc: 0.6789 - val_loss: 0.9198 - val_acc: 0.7142\n",
            "Epoch 23/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8939 - acc: 0.6766 - val_loss: 0.9428 - val_acc: 0.7206\n",
            "Epoch 24/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8834 - acc: 0.6789 - val_loss: 0.9235 - val_acc: 0.7200\n",
            "Epoch 25/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.8969 - acc: 0.6801 - val_loss: 0.8067 - val_acc: 0.7099\n",
            "Epoch 26/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8890 - acc: 0.6815 - val_loss: 0.8590 - val_acc: 0.7059\n",
            "Epoch 27/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8889 - acc: 0.6813 - val_loss: 0.8093 - val_acc: 0.7203\n",
            "Epoch 28/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8746 - acc: 0.6880 - val_loss: 0.9538 - val_acc: 0.5481\n",
            "Epoch 29/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8698 - acc: 0.6900 - val_loss: 1.0465 - val_acc: 0.5530\n",
            "Epoch 30/60\n",
            "224/224 [==============================] - 14s 62ms/step - loss: 0.8705 - acc: 0.6881 - val_loss: 0.8415 - val_acc: 0.7157\n",
            "Epoch 31/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8632 - acc: 0.6912 - val_loss: 0.8831 - val_acc: 0.7038\n",
            "Epoch 32/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8625 - acc: 0.6917 - val_loss: 1.0479 - val_acc: 0.5761\n",
            "Epoch 33/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.8665 - acc: 0.6923 - val_loss: 0.8124 - val_acc: 0.7090\n",
            "Epoch 34/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8640 - acc: 0.6945 - val_loss: 0.9912 - val_acc: 0.5744\n",
            "Epoch 35/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8505 - acc: 0.6969 - val_loss: 0.8126 - val_acc: 0.7142\n",
            "Epoch 36/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8490 - acc: 0.6980 - val_loss: 0.8454 - val_acc: 0.7140\n",
            "Epoch 37/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8560 - acc: 0.6975 - val_loss: 0.8090 - val_acc: 0.7200\n",
            "Epoch 38/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8477 - acc: 0.6974 - val_loss: 0.7962 - val_acc: 0.7223\n",
            "Epoch 39/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.8417 - acc: 0.7009 - val_loss: 0.7938 - val_acc: 0.7203\n",
            "Epoch 40/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8360 - acc: 0.6983 - val_loss: 0.8035 - val_acc: 0.7206\n",
            "Epoch 41/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8391 - acc: 0.7035 - val_loss: 0.8121 - val_acc: 0.7177\n",
            "Epoch 42/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8470 - acc: 0.7000 - val_loss: 0.7995 - val_acc: 0.7206\n",
            "Epoch 43/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8372 - acc: 0.7006 - val_loss: 0.7830 - val_acc: 0.7226\n",
            "Epoch 44/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.8282 - acc: 0.7065 - val_loss: 0.7891 - val_acc: 0.7229\n",
            "Epoch 45/60\n",
            "224/224 [==============================] - 14s 62ms/step - loss: 0.8303 - acc: 0.7039 - val_loss: 0.7830 - val_acc: 0.7301\n",
            "Epoch 46/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8234 - acc: 0.7081 - val_loss: 0.8149 - val_acc: 0.7151\n",
            "Epoch 47/60\n",
            "224/224 [==============================] - 14s 62ms/step - loss: 0.8179 - acc: 0.7111 - val_loss: 0.8080 - val_acc: 0.7197\n",
            "Epoch 48/60\n",
            "224/224 [==============================] - 14s 62ms/step - loss: 0.8178 - acc: 0.7098 - val_loss: 0.7756 - val_acc: 0.7249\n",
            "Epoch 49/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8174 - acc: 0.7131 - val_loss: 0.8128 - val_acc: 0.7200\n",
            "Epoch 50/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8166 - acc: 0.7076 - val_loss: 0.8103 - val_acc: 0.7154\n",
            "Epoch 51/60\n",
            "224/224 [==============================] - 14s 65ms/step - loss: 0.8087 - acc: 0.7136 - val_loss: 0.7991 - val_acc: 0.7235\n",
            "Epoch 52/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8170 - acc: 0.7153 - val_loss: 0.8492 - val_acc: 0.7154\n",
            "Epoch 53/60\n",
            "224/224 [==============================] - 14s 62ms/step - loss: 0.8069 - acc: 0.7157 - val_loss: 0.8025 - val_acc: 0.7206\n",
            "Epoch 54/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8000 - acc: 0.7197 - val_loss: 0.8250 - val_acc: 0.7220\n",
            "Epoch 55/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8068 - acc: 0.7134 - val_loss: 0.8180 - val_acc: 0.7180\n",
            "Epoch 56/60\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.8081 - acc: 0.7143 - val_loss: 0.8416 - val_acc: 0.7212\n",
            "Epoch 57/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.7993 - acc: 0.7167 - val_loss: 0.8592 - val_acc: 0.7093\n",
            "Epoch 58/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.7936 - acc: 0.7206 - val_loss: 0.8209 - val_acc: 0.7151\n",
            "Epoch 59/60\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.7968 - acc: 0.7208 - val_loss: 0.8586 - val_acc: 0.7104\n",
            "Epoch 60/60\n",
            "224/224 [==============================] - 14s 62ms/step - loss: 0.7890 - acc: 0.7221 - val_loss: 0.8697 - val_acc: 0.7056\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}